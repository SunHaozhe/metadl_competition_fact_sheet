{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of the CSV file which contains the label and image name\n",
    "CSV_PATH = \"./data.csv\"\n",
    "\n",
    "# True if CSV is tab separated otherwise false\n",
    "CSV_WITH_TAB = False\n",
    "\n",
    "# Path of the directory where images to be used in this experiement are saved\n",
    "IMAGE_PATH = \"./images\"\n",
    "\n",
    "# Path of the directory where the results of this experiments will bee saved\n",
    "# logs.txt, super_categories.txt and one directory for each super_category\n",
    "# which contains categories.txt, categories_auc.txt, logs.txt, some figures etc \n",
    "PREDICTIONS_PATH = \"./experiment_1_results\"\n",
    "\n",
    "\n",
    "# label column name in csv\n",
    "LABEL_COLUMN = \"Category\"\n",
    "\n",
    "# image column name in csv\n",
    "IMAGE_COLUMN = \"file_name\"\n",
    "\n",
    "# number of categories to combine to make a super-category or a classification task\n",
    "CATEGORIES_TO_COMBINE = 5\n",
    "\n",
    "# number of images per category\n",
    "# shots = IMAGES_PER_CATEGORY/2\n",
    "IMAGES_PER_CATEGORY = 20\n",
    "\n",
    "# maximum limit on episodes/super-categories\n",
    "# can be none or an integer\n",
    "MAX_EPISODES = None\n",
    "\n",
    "\n",
    "# seed for generating super-categories by the same random combination of categories\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import argparse\n",
    "\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "import copy\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "\n",
    "import gc\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "params = {'legend.fontsize': 'xx-large',\n",
    "         'axes.labelsize': 'xx-large',\n",
    "         'axes.titlesize':'xx-large',\n",
    "         'xtick.labelsize':'xx-large',\n",
    "         'ytick.labelsize':'xx-large'}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, auc, roc_curve, roc_auc_score\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_start = time.time()\n",
    "timestamp = str(datetime.datetime.utcnow().strftime(\"%Y%m%d_%H%M%S_%f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Prediction Dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(PREDICTIONS_PATH):\n",
    "    os.makedirs(PREDICTIONS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "if CSV_WITH_TAB:\n",
    "    data = pd.read_csv(CSV_PATH, sep=\"\\t\", encoding=\"utf-8\") \n",
    "else:\n",
    "    data = pd.read_csv(CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Shape : \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categoris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = data[LABEL_COLUMN].unique()\n",
    "total_categories = len(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Super Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.Random(SEED).shuffle(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations_needed = math.ceil(total_categories/CATEGORIES_TO_COMBINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Categories/Classes : \", total_categories)\n",
    "print(\"Iterations required : \", iterations_needed)\n",
    "print(\"Categories to combine togather : \", CATEGORIES_TO_COMBINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_categories = np.array_split(categories,iterations_needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_super_categories = len(super_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Super-Categories : \", total_super_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Super_Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "super_data = []\n",
    "for index, super_category in enumerate(super_categories):\n",
    "    super_dict = {}\n",
    "\n",
    "    #extracting subset of images per category\n",
    "    super_category_df = data[data[LABEL_COLUMN].isin(super_category)].groupby(LABEL_COLUMN).sample(n=IMAGES_PER_CATEGORY, random_state=SEED)\n",
    "    super_category_df['label_cat'] = super_category_df[LABEL_COLUMN].astype('category')\n",
    "    super_dict['super_category'] = str(index)\n",
    "    \n",
    "#     super_dict['categories'] = super_category_df[LABEL_COLUMN].value_counts().index.values\n",
    "    super_dict['categories'] = super_category_df['label_cat'].cat.categories.values\n",
    "    \n",
    "    \n",
    "    super_dict['images'] = super_category_df[LABEL_COLUMN].value_counts().values\n",
    "    \n",
    "    \n",
    "    train_data, valid_data = train_test_split(\n",
    "        super_category_df, test_size=0.5, \n",
    "        random_state=420, shuffle=True, \n",
    "        stratify=super_category_df[LABEL_COLUMN]\n",
    "    )\n",
    "    \n",
    "\n",
    "    \n",
    "    super_dict['train_labels'] = train_data[LABEL_COLUMN].values\n",
    "    super_dict['valid_labels'] = valid_data[LABEL_COLUMN].values\n",
    "    \n",
    "    super_dict['train_labels_num'] =  train_data['label_cat'].cat.codes.values\n",
    "    super_dict['valid_labels_num'] = valid_data['label_cat'].cat.codes.values\n",
    "    \n",
    "    \n",
    "  \n",
    "    \n",
    "    super_dict['train_data'] = train_data[IMAGE_COLUMN].values\n",
    "    super_dict['valid_data'] = valid_data[IMAGE_COLUMN].values\n",
    "    \n",
    "    super_data.append(super_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, dataset_images, dataset_labels, transform):\n",
    "\n",
    "        # Transforms\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.images = dataset_images\n",
    "        self.labels = dataset_labels\n",
    "\n",
    "        self.data_len = len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        \n",
    "        single_img = self.images[index]\n",
    "        img_transformed = torch.from_numpy(single_img).long()\n",
    "        img_transformed = img_transformed.permute(2, 0, 1)\n",
    "        img_transformed = torch.from_numpy(np.array(img_transformed)).float() / 255.\n",
    "\n",
    "        \n",
    "        single_label = self.labels[index]\n",
    "        single_label = single_label.astype(np.compat.long)\n",
    "        \n",
    "        return img_transformed, single_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(super_data_set, batch_size=64):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    train_ds=ImgDataset(super_data_set['train_images'],super_data_set['train_labels_num'], transform)\n",
    "    valid_ds=ImgDataset(super_data_set['valid_images'],super_data_set['valid_labels_num'], transform)\n",
    "    \n",
    "    print(\"############################################\")\n",
    "    print(\"============================================\")\n",
    "    print(\"=== Super-Category: \", super_data_set['super_category'])\n",
    "    print(\"============================================\")\n",
    "    print(\"############################################\")\n",
    "    print()\n",
    "    print(\"Total Categories: \", len(super_data_set['categories']))\n",
    "    print(\"Total Images: \", super_data_set['images'].sum())\n",
    "    print(\"Train Data: \", len(train_ds))\n",
    "    print(\"Validation Data: \", len(valid_ds))\n",
    "    print()\n",
    "    \n",
    "    data_stats = {\n",
    "        \"total_images\" : super_data_set['images'].sum(),\n",
    "        \"train_images\" : len(train_ds),\n",
    "        \"valid_images\" : len(valid_ds)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    dataloaders = {\n",
    "        'val':DataLoader(\n",
    "            valid_ds, \n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "        ),\n",
    "        'train':DataLoader(\n",
    "            train_ds, \n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "    }\n",
    "\n",
    "    dataset_sizes = {\n",
    "        'val': len(valid_ds),\n",
    "        'train':len(train_ds)\n",
    "    }\n",
    "    \n",
    "    return dataloaders, dataset_sizes, data_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel(only_train_last_layer=True, number_of_classes=2):\n",
    "    model = models.resnet18(pretrained=True)\n",
    "\n",
    "    if only_train_last_layer:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, number_of_classes)\n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, dataset_sizes, criterion, optimizer, scheduler, num_epochs=5):\n",
    "    \n",
    "    \n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"Training\")\n",
    "    print(\"--------------------------------------------\")\n",
    "    \n",
    "    since = time.time()\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    best_train_acc = 0.0\n",
    "    \n",
    "    loss_history = []\n",
    "    score_history = []\n",
    "    \n",
    "    \n",
    "    train_loss, train_score, valid_loss, valid_score = [], [], [], []\n",
    "\n",
    "    print(\"Epoch: \", end=\" \")\n",
    "    for epoch in range(num_epochs):\n",
    "        print(epoch, end=\" \")\n",
    "        \n",
    "        train_predictions, train_ground, valid_predictions, valid_ground = [], [], [], []\n",
    "        train_predicted_probabilities, valid_predicted_probabilities = [],[]\n",
    "        \n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    \n",
    "#                     inputs = inputs.permute(0, 3, 1, 2)\n",
    "#                     inputs = torch.from_numpy(np.array(inputs)).float() / 255.\n",
    "                    \n",
    "                    outputs = model(inputs)\n",
    "                    probabilities = F.softmax(outputs, dim=1)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                 \n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                # saving prediction and ground truth for future use\n",
    "                if phase == 'train':\n",
    "                    train_predictions += list(preds.numpy())\n",
    "                    train_ground += list(labels.numpy())\n",
    "                    train_predicted_probabilities += list(probabilities.detach().numpy())\n",
    "                else:\n",
    "                    valid_predictions += list(preds.numpy())\n",
    "                    valid_ground += list(labels.numpy())\n",
    "                    valid_predicted_probabilities += list(probabilities.detach().numpy())\n",
    "                \n",
    "                \n",
    "            # end dataloader loop\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "#                 loss_history.append(running_loss)\n",
    "#                 score_history.append(running_corrects)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = (running_corrects.double() / dataset_sizes[phase]).item()\n",
    "\n",
    "#             print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            loss_history, score_history = (train_loss, train_score) if phase == 'train' else (valid_loss, valid_score)\n",
    "            loss_history.append(epoch_loss)\n",
    "            score_history.append(epoch_acc)\n",
    "\n",
    "            \n",
    "            if phase == 'train' and epoch_acc > best_train_acc:\n",
    "                 best_train_acc = epoch_acc\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_val_acc:\n",
    "                best_val_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        # end phase loop\n",
    "        \n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    training_time = '{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)\n",
    "    \n",
    "    print('Training complete in: {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best train Acc: {:.2f}'.format(best_train_acc))\n",
    "    print('Best val Acc: {:.2f}'.format(best_val_acc))\n",
    "    print()\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return dict(   \n",
    "        model = model,\n",
    "        train_loss = train_loss,\n",
    "        train_score = train_score,\n",
    "        train_best_score = round(best_train_acc,2),\n",
    "        train_ground = train_ground,\n",
    "        train_predictions = train_predictions,\n",
    "        train_predicted_probabilities = np.array(train_predicted_probabilities),\n",
    "        valid_loss = valid_loss,\n",
    "        valid_score = valid_score,\n",
    "        valid_best_score = round(best_val_acc,2),\n",
    "        valid_ground = valid_ground,\n",
    "        valid_predictions = valid_predictions,\n",
    "        valid_predicted_probabilities =  np.array(valid_predicted_probabilities),\n",
    "        training_time = training_time\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_results(train_results, super_category):\n",
    "    \n",
    "    \n",
    "    standard_error = train_results['standard_error']\n",
    "    y_upper = train_results[\"valid_score\"] + standard_error\n",
    "    y_lower = train_results[\"valid_score\"] - standard_error\n",
    "    \n",
    "\n",
    "    \n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"Results\")\n",
    "    print(\"--------------------------------------------\")\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,8))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(0,len(train_results[\"train_score\"])), train_results[\"train_score\"], label='train')\n",
    "\n",
    "    plt.plot(range(0,len(train_results[\"valid_score\"])), train_results[\"valid_score\"], label='valid')\n",
    "    \n",
    "    \n",
    "    kwargs = {'color': 'black', 'linewidth': 1, 'linestyle': '--', 'dashes':(5, 5)}\n",
    "    plt.plot(range(0,len(train_results[\"valid_score\"])), y_lower, **kwargs)\n",
    "    plt.plot(range(0,len(train_results[\"valid_score\"])), y_upper, **kwargs, label='validation SE (68% CI)')\n",
    "    \n",
    "    \n",
    "    plt.title('Accuracy Plot - ' + super_category, fontsize=20)\n",
    "    plt.ylabel('Accuracy', fontsize=16)\n",
    "    plt.xlabel('Training Epochs', fontsize=16)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(0,len(train_results[\"train_loss\"])), train_results[\"train_loss\"], label='train')\n",
    "    plt.plot(range(0,len(train_results[\"valid_loss\"])), train_results[\"valid_loss\"], label='valid')\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.title('Loss Plot - ' + super_category, fontsize=20)\n",
    "    plt.ylabel('Loss', fontsize=16)\n",
    "    plt.xlabel('Training Epochs', fontsize=16)\n",
    "    max_train_loss = max(train_results[\"train_loss\"])\n",
    "    max_valid_loss = max(train_results[\"valid_loss\"])\n",
    "    y_max_t_v = max_valid_loss if max_valid_loss > max_train_loss else max_train_loss\n",
    "    ylim_loss = y_max_t_v if y_max_t_v > 1 else 1\n",
    "    plt.ylim(0, ylim_loss)\n",
    "    plt.legend()\n",
    "\n",
    "  \n",
    "    plt.show()\n",
    "    \n",
    "    super_category_path = os.path.join(PREDICTIONS_PATH,super_category, \"train_results.png\")\n",
    "    fig.savefig(super_category_path, dpi=fig.dpi)\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_error_bar(best_score, valid_examples):\n",
    "    \n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"Standard Error\")\n",
    "    print(\"--------------------------------------------\")\n",
    "    \n",
    "\n",
    "    \n",
    "    err = np.sqrt((best_score * (1-best_score))/valid_examples)\n",
    "    err_rounded_68 = round(err,2)\n",
    "    err_rounded_95 = round((err_rounded_68 * 2),2)\n",
    "   \n",
    "    print('Error (68% CI): +- ' + str(err_rounded_68))\n",
    "    print('Error (95% CI): +- ' + str(err_rounded_95))\n",
    "    print()\n",
    "    return err_rounded_68\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(grounds, preds, super_category, categories):\n",
    "    \n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(\"--------------------------------------------\")\n",
    "    \n",
    "    num_cat = []\n",
    "    for ind, cat in enumerate(categories):\n",
    "        print(\"Class {0} : {1}\".format(ind, cat))\n",
    "        num_cat.append(ind)\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    \n",
    "    cm = confusion_matrix(grounds, preds, labels=num_cat)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    ax = fig.add_subplot()\n",
    "    sns.heatmap(cm, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "    # labels, title and ticks\n",
    "    ax.set_title('Confusion Matrix - '+ super_category, fontsize=20)\n",
    "    ax.set_xlabel('Predicted labels', fontsize=16)\n",
    "    ax.set_ylabel('True labels', fontsize=16)\n",
    "    \n",
    "    ax.xaxis.set_ticklabels(num_cat)\n",
    "    ax.yaxis.set_ticklabels(num_cat)\n",
    "    \n",
    "    plt.pause(0.1)\n",
    "    super_category_path = os.path.join(PREDICTIONS_PATH,super_category, \"confusion_matrix.png\")\n",
    "    fig.savefig(super_category_path, dpi=fig.dpi)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Plot Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_images(super_category, grounds, train_images):\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"Sample Images - \", super_category)\n",
    "    print(\"--------------------------------------------\")\n",
    "\n",
    "    \n",
    "    uniques, indexes = np.unique(grounds, return_index=True)\n",
    "    \n",
    "\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    k=0\n",
    "    for i in range(0, len(indexes)):\n",
    "        fig.add_subplot(1,5,k+1)\n",
    "        plt.axis('off')\n",
    "        title = \"Label : \"+ str(uniques[i])\n",
    "        plt.title(title,fontsize=16)\n",
    "        plt.imshow(train_images[uniques[i]])\n",
    "        k += 1\n",
    "    plt.pause(0.1)\n",
    "    print()   \n",
    "    \n",
    "    super_category_path = os.path.join(PREDICTIONS_PATH,super_category, \"sample_images.png\")\n",
    "    fig.savefig(super_category_path, dpi=fig.dpi, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Wrongly Classified Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wrongly_classified_images(super_category, grounds, preds, valid_images):\n",
    "    \n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"Wrongly Classified Images - \", super_category)\n",
    "    print(\"--------------------------------------------\")\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    k=0\n",
    "    for i in range(0, len(grounds)):\n",
    "        if grounds[i] != preds[i]:\n",
    "            \n",
    "            fig.add_subplot(1,5,k+1)\n",
    "            plt.axis('off')\n",
    "            title = \"Orig lbl: \"+ str(grounds[i]) + \" Pred lbl: \" + str(preds[i])\n",
    "            plt.title(title, fontsize=16)\n",
    "            plt.imshow(valid_images[i])\n",
    "            k += 1\n",
    "        if k == 5:\n",
    "            break\n",
    "    plt.pause(0.1)\n",
    "    print()\n",
    "    \n",
    "    super_category_path = os.path.join(PREDICTIONS_PATH,super_category, \"wrongly_classified_images.png\")\n",
    "    fig.savefig(super_category_path, dpi=fig.dpi, bbox_inches='tight')\n",
    "    \n",
    "def get_wrongly_classified_images_indexes(grounds, preds):\n",
    "    wrong_images_indexes = []\n",
    "    for i in range(0, len(grounds)):\n",
    "        if grounds[i] != preds[i]:\n",
    "            wrong_images_indexes.append(i)\n",
    "    return wrong_images_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autodl_auc(outputs, targets, predictions):\n",
    "    \n",
    "    targets = np.asarray(targets)\n",
    "    predictions = np.asarray(predictions)\n",
    "    \n",
    "    numclass = targets.max()+1\n",
    "    \n",
    "    boolean_array = np.zeros((len(outputs),numclass), dtype=bool)\n",
    "    \n",
    "    for labelindex in range(numclass):\n",
    "        boolean_array[:,labelindex]= (targets == labelindex)\n",
    "    \n",
    "    \n",
    "    auc = roc_auc_score(boolean_array, outputs)\n",
    "    auc_1 = 2*auc-1\n",
    "    \n",
    "    \n",
    "    return round(auc, 2), round(auc_1, 2)\n",
    "   \n",
    "\n",
    "\n",
    "def plot_auc(outputs, targets, predictions, autodl_auc_0,autodl_auc_1, super_category, categories):\n",
    "    \n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"Average AUC\")\n",
    "    print(\"--------------------------------------------\")\n",
    "    \n",
    "    print(\"AUC : \", autodl_auc_0)\n",
    "    print(\"2*AUC-1 : \", autodl_auc_1)\n",
    "    print()\n",
    "    \n",
    "\n",
    "    \n",
    "    targets = np.asarray(targets)\n",
    "    predictions = np.asarray(predictions)\n",
    "    \n",
    "    \n",
    "    \n",
    "    numclass = len(categories) #targets.max()+1 \n",
    "    \n",
    "    scores_auroc = []\n",
    "    scores_auroc_1 =[]\n",
    "\n",
    "    for labelindex in range(numclass):\n",
    "        binary_targets = (targets == labelindex)\n",
    "        binary_predictions = (predictions == labelindex)\n",
    "       \n",
    "        selected_outputs = outputs[:,labelindex]\n",
    "  \n",
    "        auroc = roc_auc_score(binary_targets, selected_outputs)\n",
    "        \n",
    "        scores_auroc.append(auroc)\n",
    "        scores_auroc_1.append(2*auroc-1)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #save categories auc  \n",
    "    categories_auc_textfile_path = os.path.join(PREDICTIONS_PATH, super_category, 'categories_auc.txt') \n",
    "    with open(categories_auc_textfile_path, 'w') as f:\n",
    "        for i,cat in enumerate(categories):\n",
    "            single_auroc = round(scores_auroc[i], 2)\n",
    "            \n",
    "            f.write(\"%s : %s\\n\" %(cat,single_auroc))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    average_auc = round(np.mean(scores_auroc), 2)\n",
    "    average_auc_1 = round(np.mean(scores_auroc_1), 2)\n",
    "    if average_auc_1 == 0.0:\n",
    "        average_auc_1 = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Plot AUC Score\n",
    "    ymin = np.min(scores_auroc_1) if np.min(scores_auroc_1) < 0  else 0\n",
    "    width = 0.2\n",
    "    \n",
    "    fig = plt.figure(figsize=(3*numclass,8))\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.bar(np.arange(numclass), scores_auroc, width,  label='AUC')\n",
    "    plt.bar(np.arange(numclass)+width, scores_auroc_1, width, label='2*AUC-1')\n",
    "    plt.hlines(y=0.0, xmin=-width, xmax=numclass-1+width*2, linewidth=1, linestyles='-', color='black')\n",
    "    plt.hlines(y=average_auc, xmin=-width, xmax=numclass-1+width*2, linewidth=2, linestyles='--', color='b', label='Average AUC : %0.2f'%average_auc)\n",
    "    plt.hlines(y=average_auc_1, xmin=-width, xmax=numclass-1+width*2, linewidth=2, linestyles='--', color='r', label='Average 2*AUC-1 : %0.2f'%average_auc_1)\n",
    "    plt.title('AUC Score - ' + super_category, fontsize=20)\n",
    "    plt.ylabel('AUC Score', fontsize=16)\n",
    "    plt.xlabel('Classes', fontsize=16)\n",
    "    plt.ylim(ymin,1)\n",
    "    plt.xticks(np.arange(numclass) + width / 2, np.arange(numclass))\n",
    "    plt.legend()\n",
    "#     plt.show()\n",
    "    plt.pause(0.1)\n",
    "    \n",
    "    super_category_path = os.path.join(PREDICTIONS_PATH,super_category, \"auc.png\")\n",
    "    fig.savefig(super_category_path, dpi=fig.dpi)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # histogram\n",
    "    fig = plt.figure(figsize=(8,5))\n",
    "    plt.title('AUC Histogram', fontsize=20)\n",
    "    plt.xlabel('AUC Score', fontsize=16)\n",
    "    plt.ylabel('Frequency', fontsize=16)\n",
    "    plt.hist(scores_auroc, alpha=0.5, ec='black')\n",
    "    plt.pause(0.1)\n",
    "    super_category_path = os.path.join(PREDICTIONS_PATH,super_category, \"auc_histogram.png\")\n",
    "    fig.savefig(super_category_path, dpi=fig.dpi)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curves(train_outputs, train_targets, train_predictions, valid_outputs, valid_targets, valid_predictions, super_category):\n",
    "    \n",
    "    print(\"--------------------------------------------\")\n",
    "    print(\"ROC Curves\")\n",
    "    print(\"--------------------------------------------\")\n",
    "    \n",
    "    \n",
    "   \n",
    "    train_targets = np.asarray(train_targets)\n",
    "    train_predictions = np.asarray(train_predictions)\n",
    "    valid_targets = np.asarray(valid_targets)\n",
    "    valid_predictions = np.asarray(valid_predictions)\n",
    "    \n",
    "    \n",
    "    numclass = train_predictions.max()+1 \n",
    "    \n",
    "    \n",
    "    train_auc_curves = []\n",
    "    valid_auc_curves = []\n",
    "\n",
    "    for labelindex in range(numclass):\n",
    "        train_binary_targets = (train_targets == labelindex)\n",
    "        train_binary_predictions = (train_predictions == labelindex)\n",
    "        \n",
    "        valid_binary_targets = (valid_targets == labelindex)\n",
    "        valid_binary_predictions = (valid_predictions == labelindex)\n",
    "       \n",
    "        selected_train_outputs = train_outputs[:,labelindex]\n",
    "        selected_valid_outputs = valid_outputs[:,labelindex]\n",
    "        \n",
    "        train_fpr, train_tpr, _ = roc_curve(train_binary_targets, selected_train_outputs)\n",
    "        valid_fpr, valid_tpr, _ = roc_curve(valid_binary_targets, selected_valid_outputs)\n",
    "       \n",
    "        train_auc_curves.append([train_fpr,train_tpr])\n",
    "        valid_auc_curves.append([valid_fpr,valid_tpr])\n",
    "        \n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "     # Plot ROC Curves\n",
    "\n",
    "   \n",
    "    fig = plt.figure(figsize=(20,8))\n",
    "   \n",
    "    plt.subplot(1,2,1)\n",
    "    for idx, auc_cur in enumerate(train_auc_curves): \n",
    "        plt.plot(auc_cur[0], auc_cur[1], marker='.',  label='Class:'+str(idx))\n",
    "    plt.plot([0,1], [0,1], linestyle='--', color='black')\n",
    "    plt.title('Train ROC Curves - ' + super_category, fontsize=20)\n",
    "    plt.ylabel('True Positive Rate', fontsize=16)\n",
    "    plt.xlabel('False Positive Rate', fontsize=16)\n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    for idx, auc_cur in enumerate(valid_auc_curves): \n",
    "        plt.plot(auc_cur[0], auc_cur[1], marker='.',  label='Class:'+str(idx))\n",
    "    plt.plot([0,1], [0,1], linestyle='--', color='black')\n",
    "    plt.title('Valid ROC Curves - ' + super_category, fontsize=20)\n",
    "    plt.ylabel('True Positive Rate', fontsize=16)\n",
    "    plt.xlabel('False Positive Rate', fontsize=16)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.pause(0.1)\n",
    "    \n",
    "    super_category_path = os.path.join(PREDICTIONS_PATH,super_category, \"roc_curves.png\")\n",
    "    fig.savefig(super_category_path, dpi=fig.dpi)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(super_category, categories, training_result):\n",
    "\n",
    "    train_dic_for_df = {}\n",
    "    valid_dic_for_df = {}\n",
    "\n",
    "\n",
    "    train_dic_for_df['ground_truth'] = training_result['train_ground']\n",
    "    train_dic_for_df['predictions'] = training_result['train_predictions']\n",
    "    \n",
    "    valid_dic_for_df['ground_truth'] = training_result['valid_ground']\n",
    "    valid_dic_for_df['predictions'] = training_result['valid_predictions']\n",
    "\n",
    "    train_probability_array = list(training_result['train_predicted_probabilities'].T)\n",
    "    valid_probability_array = list(training_result['valid_predicted_probabilities'].T)\n",
    "    for idx, prob in enumerate(train_probability_array):\n",
    "        key = 'prob_'+str(idx)\n",
    "        train_dic_for_df[key] = prob\n",
    "    for idx, prob in enumerate(valid_probability_array):\n",
    "        key = 'prob_'+str(idx)\n",
    "        valid_dic_for_df[key] = prob\n",
    "\n",
    "\n",
    "    train_df = pd.DataFrame(train_dic_for_df)\n",
    "    valid_df = pd.DataFrame(valid_dic_for_df)\n",
    "    \n",
    "\n",
    "    \n",
    "    csv_train = os.path.join(PREDICTIONS_PATH, super_category, 'train.csv') \n",
    "    csv_valid = os.path.join(PREDICTIONS_PATH, super_category, 'valid.csv') \n",
    "    \n",
    "\n",
    "    #save train valid_predictions_ground_probabilities in CSV  \n",
    "    train_df.to_csv(csv_train, index=False)\n",
    "    valid_df.to_csv(csv_valid, index=False)\n",
    "\n",
    "    \n",
    "    #save categories  \n",
    "    categories_textfile_path = os.path.join(PREDICTIONS_PATH, super_category, 'categories.txt') \n",
    "    with open(categories_textfile_path, 'w') as f:\n",
    "        for item in categories:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "    \n",
    "    #save category logs\n",
    "    category_logfile_path = os.path.join(PREDICTIONS_PATH, super_category, 'logs.txt') \n",
    "    with open(category_logfile_path, 'w') as f:\n",
    "        f.write(\"Total Images : %s\\n\" % training_result['total_images'])\n",
    "        f.write(\"Training Images : %s\\n\" % training_result['train_images'])\n",
    "        f.write(\"Validation Images : %s\\n\" % training_result['valid_images'])\n",
    "        f.write(\"Training Time : %s\\n\" % training_result['training_time'])\n",
    "        f.write(\"Best Train Accuracy : %s\\n\" % training_result['train_best_score'])\n",
    "        f.write(\"Best Valid Accuracy : %s\\n\" % training_result['valid_best_score'])\n",
    "        f.write(\"AUC : %s\\n\" % training_result['AUC'])\n",
    "        f.write(\"2*AUC-1 : %s\\n\" % training_result['AUC_1'])\n",
    "        f.write(\"Standard Error : %s\\n\" % training_result['standard_error'])\n",
    "        \n",
    "\n",
    "    \n",
    "    print(\"Saved Results for Super-Category : \", super_category)\n",
    "    print()\n",
    "    print()\n",
    "        \n",
    "    #save super-category\n",
    "    super_categories_textfile_path = os.path.join(PREDICTIONS_PATH, 'super_categories.txt') \n",
    "    with open(super_categories_textfile_path, 'a') as f:\n",
    "        f.write(\"%s\\n\" % super_category)\n",
    "        \n",
    "        \n",
    "def save_overall_logs():\n",
    "    #save logs \n",
    "    overall_logsfile_path = os.path.join(PREDICTIONS_PATH, 'logs.txt') \n",
    "    with open(overall_logsfile_path, 'w') as f:\n",
    "        f.write(\"Total Super Categories : %s\\n\" % total_super_categories)\n",
    "        f.write(\"Total Categories : %s\\n\" % total_categories)\n",
    "        f.write(\"Iterations Needed : %s\\n\" % iterations_needed)\n",
    "        f.write(\"Classes to Combine : %s\\n\" % CATEGORIES_TO_COMBINE)\n",
    "        \n",
    "    print(\"#################################\")\n",
    "    print(\"Saved Overall logs of experiment\")\n",
    "    print(\"#################################\")\n",
    "        \n",
    "        \n",
    "        \n",
    "def make_super_category_directory(super_category):\n",
    "    \n",
    "    super_category_path = os.path.join(PREDICTIONS_PATH,super_category)\n",
    "    if not os.path.exists(super_category_path):\n",
    "        os.makedirs(super_category_path)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate overall histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_range(dictionary, begin, end):\n",
    "    return dict(e for i, e in enumerate(dictionary.items()) if begin <= i <= end)\n",
    "\n",
    "\n",
    "def generate_overall_auc_histogram_and_desc_auc_plot():\n",
    "    \n",
    "    #Read super_Categories\n",
    "    super_categories_textfile_path = os.path.join(PREDICTIONS_PATH, 'super_categories.txt') \n",
    "    with open(super_categories_textfile_path, 'r') as f:\n",
    "        super_categories = f.read().splitlines()\n",
    "        \n",
    "    #Read Categories AUC    \n",
    "    categories_dic = {}\n",
    "    for sup_cat in super_categories:\n",
    "        categories_auc_textfile_path = os.path.join(PREDICTIONS_PATH, sup_cat, 'categories_auc.txt') \n",
    "        with open(categories_auc_textfile_path, 'r') as f:\n",
    "            categories_auc = f.read().splitlines()\n",
    "        for item in categories_auc:\n",
    "            arr_split = item.split(' : ')\n",
    "            categories_dic[arr_split[0]] = float(arr_split[1])\n",
    "            \n",
    "    #Sort in descending order        \n",
    "    sorted_categories_dic = dict(sorted(categories_dic.items(), key=lambda x: x[1], reverse=True))\n",
    "    \n",
    "    \n",
    "    print(\"##########################################\")\n",
    "    print(\"Saving Overall AUC Histogram\")\n",
    "    print(\"##########################################\")\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    #plot histogram\n",
    "    fig = plt.figure(figsize=(15,8))\n",
    "    plt.title('All CategoriesAUC Histogram', fontsize=20)\n",
    "    plt.xlabel('AUC Score', fontsize=16)\n",
    "    plt.ylabel('Frequency', fontsize=16)\n",
    "    plt.hist(list(sorted_categories_dic.values()), alpha=0.5, ec='black')\n",
    "    plt.show()\n",
    "    overall_categoris_auc_histogram_path = os.path.join(PREDICTIONS_PATH, \"overall_auc_histogram.png\")\n",
    "    fig.savefig(overall_categoris_auc_histogram_path, dpi=fig.dpi)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"##########################################\")\n",
    "    print(\"Saving Desc AUC Plot\")\n",
    "    print(\"##########################################\")\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    total_cat = len(sorted_categories_dic)\n",
    "    cat_per_plot = 30\n",
    "    plots_needed = math.ceil(len(sorted_categories_dic)/cat_per_plot)\n",
    "\n",
    "    print(\"Total Categories : \", total_cat)\n",
    "    print(\"Plots Needed : \", plots_needed)\n",
    "    print(\"Categories per plot : \", cat_per_plot)\n",
    "    \n",
    "    fig, axs = plt.subplots(plots_needed,1, figsize=(20, plots_needed*cat_per_plot))\n",
    "    fig.subplots_adjust(hspace = .1, wspace=.001)\n",
    "    axs = axs.ravel()\n",
    "\n",
    "    for i in range(plots_needed):\n",
    "        begin = i*cat_per_plot\n",
    "        end = (i*cat_per_plot+cat_per_plot-1) if (i*cat_per_plot+cat_per_plot-1) < total_cat else total_cat \n",
    "        slice_i = get_range(sorted_categories_dic, begin, end)\n",
    "\n",
    "        axs[i].barh(list(slice_i.keys()), list(slice_i.values()))\n",
    "        axs[i].set_title(\"All Categories AUC - Slice \"+ str(i+1), fontsize=20)\n",
    "        axs[i].xaxis.set_tick_params(rotation=90)\n",
    "        axs[i].set_xlabel(\"AUC Score\")\n",
    "        axs[i].set_ylabel(\"Category\")\n",
    "        axs[i].invert_yaxis()\n",
    "        ymin,ymax=axs[i].get_ylim()\n",
    "        axs[i].vlines(0.5, ymin=ymin, ymax=ymax, linestyles =\"--\", colors =\"r\")\n",
    "\n",
    "\n",
    "    descending_categoris_auc_path = os.path.join(PREDICTIONS_PATH, \"descending_auc.png\")\n",
    "    fig.savefig(descending_categoris_auc_path, dpi=fig.dpi)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magic Happens here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(single_super_data):\n",
    "        \n",
    "    train_images = []\n",
    "    valid_images = []\n",
    "    \n",
    "    for image_name in single_super_data['train_data']:\n",
    "        file = IMAGE_PATH+\"/\"+image_name\n",
    "        img = cv2.imread(file)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        train_images.append(img_rgb)\n",
    "\n",
    "    for image_name in single_super_data['valid_data']:\n",
    "        file = IMAGE_PATH+\"/\"+image_name\n",
    "        img = cv2.imread(file)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        valid_images.append(img_rgb)\n",
    "        \n",
    "    single_super_data['train_images'] = train_images\n",
    "    single_super_data['valid_images'] = valid_images\n",
    "    return single_super_data\n",
    "\n",
    "\n",
    "\n",
    "def train_single_super_category(single_super_data):\n",
    "    \n",
    "    single_super_data = load_images(single_super_data)\n",
    "    \n",
    "\n",
    "    dataloaders, dataset_sizes, data_stats = make_dataset(single_super_data)\n",
    "    model = getModel(number_of_classes=len(single_super_data['categories']))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "    result = train_model(model, dataloaders, dataset_sizes, criterion, optimizer, exp_lr_scheduler, num_epochs=10)\n",
    "    \n",
    "    \n",
    "    #data statistics\n",
    "    result['total_images'] = data_stats['total_images']\n",
    "    result['train_images'] = data_stats['train_images']\n",
    "    result['valid_images'] = data_stats['valid_images']\n",
    "    \n",
    "    \n",
    "    \n",
    "    # make directory for storing results\n",
    "    make_super_category_directory(single_super_data['super_category'])\n",
    "\n",
    "    #Accuracy, Loss and Error\n",
    "    result['standard_error'] = get_error_bar(result['valid_best_score'], len(single_super_data['valid_images']))\n",
    "    plot_train_results(result, single_super_data['super_category'])\n",
    "    \n",
    "        \n",
    "    #Confusion Matrix\n",
    "    plot_confusion_matrix(result['valid_ground'], result['valid_predictions'], single_super_data['super_category'], single_super_data['categories'])\n",
    "    \n",
    "    #AUC\n",
    "    autodl_auc_0 , autodl_auc_1 = autodl_auc(result['valid_predicted_probabilities'], result['valid_ground'], result['valid_predictions'])\n",
    "    result['AUC'] = autodl_auc_0\n",
    "    result['AUC_1'] = autodl_auc_1\n",
    "    plot_auc(result['valid_predicted_probabilities'], result['valid_ground'], result['valid_predictions'],autodl_auc_0, autodl_auc_1, single_super_data['super_category'], single_super_data['categories'])\n",
    "    \n",
    "    \n",
    "    #ROC Curves\n",
    "    plot_roc_curves(result['train_predicted_probabilities'], result['train_ground'], result['train_predictions'],\n",
    "            result['valid_predicted_probabilities'], result['valid_ground'], result['valid_predictions']\n",
    "            , single_super_data['super_category'])\n",
    "    \n",
    "    #Sample Images\n",
    "    plot_sample_images(single_super_data['super_category'], result['train_ground'], single_super_data['train_images'])\n",
    "    \n",
    "    #Wrong Images\n",
    "    plot_wrongly_classified_images(single_super_data['super_category'], result['valid_ground'], result['valid_predictions'], single_super_data['valid_images'])\n",
    "    \n",
    "    #Save Predictions\n",
    "    save_predictions(single_super_data['super_category'], single_super_data['categories'], result)\n",
    "\n",
    "    \n",
    "    \n",
    "    #CleanUp\n",
    "    del dataloaders\n",
    "    del model\n",
    "    del criterion\n",
    "    del optimizer\n",
    "    del exp_lr_scheduler\n",
    "    \n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save overall logs\n",
    "save_overall_logs()\n",
    "\n",
    "# loop over all random super-categories to get results per super-category\n",
    "for index, singlee_super_data in enumerate(super_data):\n",
    "    if MAX_EPISODES is None or index < MAX_EPISODES:\n",
    "        super_results[singlee_super_data['super_category']] = train_single_super_category(singlee_super_data)\n",
    "\n",
    "\n",
    "\n",
    "#generate over all hostogram and auc desc plot\n",
    "generate_overall_auc_histogram_and_desc_auc_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The whole process done in {:.2f} s.\".format(time.time() - t0_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
